{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='in_hospital_mortality/../../data/in-hospital-mortality/', deep_supervision=False, depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch99.test0.28652081384.state', lr=0.001, mode='test', network='models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='.', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model models/lstm.py\n",
      "==> not used params in network class: ['verbose', 'timestep', 'epochs', 'header', 'prefix', 'load_state', 'optimizer', 'network', 'lr', 'output_dir', 'mode', 'size_coef', 'target_repl_coef', 'batch_size', 'data', 'save_every', 'beta_1', 'imputation', 'l2', 'small_part', 'l1', 'normalizer_state']\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "==> model.final_name: k_lstm.n16.d0.3.dep2.bs8.ts1.0\n",
      "==> compiling the model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 16)          5440      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,569\n",
      "Trainable params: 7,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2019-06-20 02:21:57.758960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-20 02:21:57.759631: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x558bcb364910 executing computations on platform CUDA. Devices:\n",
      "2019-06-20 02:21:57.759662: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2019-06-20 02:21:57.762284: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-06-20 02:21:57.762482: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x558bcb3cd470 executing computations on platform Host. Devices:\n",
      "2019-06-20 02:21:57.762510: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-20 02:21:57.762885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 15.75GiB freeMemory: 15.34GiB\n",
      "2019-06-20 02:21:57.762911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-20 02:21:58.238980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-20 02:21:58.239052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-20 02:21:58.239062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-20 02:21:58.239436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14839 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "2019-06-20 02:23:36.883607: I tensorflow/stream_executor/dso_loader.cc:153] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "3236/3236 [==============================] - 34s 11ms/step\n",
      "confusion matrix:\n",
      "[[2792   70]\n",
      " [ 267  107]]\n",
      "accuracy = 0.895859062672\n",
      "precision class 0 = 0.912716567516\n",
      "precision class 1 = 0.604519784451\n",
      "recall class 0 = 0.975541591644\n",
      "recall class 1 = 0.28609624505\n",
      "AUC of ROC = 0.850444885406\n",
      "AUC of PRC = 0.483550639337\n",
      "min(+P, Se) = 0.481382978723\n"
     ]
    }
   ],
   "source": [
    "!python in_hospital_mortality/main.py --network models/lstm.py --dim 16 --timestep 1.0 --depth 2 --dropout 0.3 --mode test --batch_size 8 --load_state in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch99.test0.28652081384.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='in_hospital_mortality/../../data/in-hospital-mortality/', deep_supervision=False, depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch27.test0.284681551681.state', lr=0.001, mode='test', network='models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='.', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model models/lstm.py\n",
      "==> not used params in network class: ['verbose', 'timestep', 'epochs', 'header', 'prefix', 'load_state', 'optimizer', 'network', 'lr', 'output_dir', 'mode', 'size_coef', 'target_repl_coef', 'batch_size', 'data', 'save_every', 'beta_1', 'imputation', 'l2', 'small_part', 'l1', 'normalizer_state']\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "==> model.final_name: k_lstm.n16.d0.3.dep2.bs8.ts1.0\n",
      "==> compiling the model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 16)          5440      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,569\n",
      "Trainable params: 7,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2019-06-20 02:56:27.784618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-20 02:56:27.785280: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x55a86f9e6d30 executing computations on platform CUDA. Devices:\n",
      "2019-06-20 02:56:27.785315: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2019-06-20 02:56:27.787828: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-06-20 02:56:27.788066: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x55a86fa4f870 executing computations on platform Host. Devices:\n",
      "2019-06-20 02:56:27.788097: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-20 02:56:27.788509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 15.75GiB freeMemory: 15.34GiB\n",
      "2019-06-20 02:56:27.788536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-20 02:56:28.284287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-20 02:56:28.284354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-20 02:56:28.284366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-20 02:56:28.284813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14839 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "2019-06-20 02:58:08.940332: I tensorflow/stream_executor/dso_loader.cc:153] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "3236/3236 [==============================] - 34s 11ms/step\n",
      "confusion matrix:\n",
      "[[2757  105]\n",
      " [ 225  149]]\n",
      "accuracy = 0.89802223444\n",
      "precision class 0 = 0.924547255039\n",
      "precision class 1 = 0.586614191532\n",
      "recall class 0 = 0.963312387466\n",
      "recall class 1 = 0.398395717144\n",
      "AUC of ROC = 0.857788951296\n",
      "AUC of PRC = 0.488045631305\n",
      "min(+P, Se) = 0.485411140584\n"
     ]
    }
   ],
   "source": [
    "!python in_hospital_mortality/main.py --network models/lstm.py --dim 16 --timestep 1.0 --depth 2 --dropout 0.3 --mode test --batch_size 8 --load_state in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch27.test0.284681551681.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='in_hospital_mortality/../../data/in-hospital-mortality/', deep_supervision=False, depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch43.test0.28904680106.state', lr=0.001, mode='test', network='models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='.', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model models/lstm.py\n",
      "==> not used params in network class: ['verbose', 'timestep', 'epochs', 'header', 'prefix', 'load_state', 'optimizer', 'network', 'lr', 'output_dir', 'mode', 'size_coef', 'target_repl_coef', 'batch_size', 'data', 'save_every', 'beta_1', 'imputation', 'l2', 'small_part', 'l1', 'normalizer_state']\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "==> model.final_name: k_lstm.n16.d0.3.dep2.bs8.ts1.0\n",
      "==> compiling the model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 16)          5440      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,569\n",
      "Trainable params: 7,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2019-06-20 03:01:39.209074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-20 03:01:39.209719: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x56477b4718a0 executing computations on platform CUDA. Devices:\n",
      "2019-06-20 03:01:39.209753: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2019-06-20 03:01:39.212418: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-06-20 03:01:39.212672: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x56477b4da410 executing computations on platform Host. Devices:\n",
      "2019-06-20 03:01:39.212771: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-20 03:01:39.213200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 15.75GiB freeMemory: 15.34GiB\n",
      "2019-06-20 03:01:39.213229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-20 03:01:39.714006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-20 03:01:39.714074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-20 03:01:39.714085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-20 03:01:39.714520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14839 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "2019-06-20 03:03:24.853334: I tensorflow/stream_executor/dso_loader.cc:153] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "3236/3236 [==============================] - 34s 11ms/step\n",
      "confusion matrix:\n",
      "[[2794   68]\n",
      " [ 268  106]]\n",
      "accuracy = 0.896168112755\n",
      "precision class 0 = 0.912475526333\n",
      "precision class 1 = 0.609195411205\n",
      "recall class 0 = 0.9762403965\n",
      "recall class 1 = 0.283422470093\n",
      "AUC of ROC = 0.855742029993\n",
      "AUC of PRC = 0.482977057173\n",
      "min(+P, Se) = 0.484042553191\n"
     ]
    }
   ],
   "source": [
    "!python in_hospital_mortality/main.py --network models/lstm.py --dim 16 --timestep 1.0 --depth 2 --dropout 0.3 --mode test --batch_size 8 --load_state in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch43.test0.28904680106.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='in_hospital_mortality/../../data/in-hospital-mortality/', deep_supervision=False, depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch28.test0.285991463893.state', lr=0.001, mode='test', network='models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='.', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model models/lstm.py\n",
      "==> not used params in network class: ['verbose', 'timestep', 'epochs', 'header', 'prefix', 'load_state', 'optimizer', 'network', 'lr', 'output_dir', 'mode', 'size_coef', 'target_repl_coef', 'batch_size', 'data', 'save_every', 'beta_1', 'imputation', 'l2', 'small_part', 'l1', 'normalizer_state']\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "==> model.final_name: k_lstm.n16.d0.3.dep2.bs8.ts1.0\n",
      "==> compiling the model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 16)          5440      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,569\n",
      "Trainable params: 7,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2019-06-20 03:08:45.806480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-20 03:08:45.807131: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x563a88aa1b70 executing computations on platform CUDA. Devices:\n",
      "2019-06-20 03:08:45.807165: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2019-06-20 03:08:45.810610: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-06-20 03:08:45.810791: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x563a88b0a6c0 executing computations on platform Host. Devices:\n",
      "2019-06-20 03:08:45.810818: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-20 03:08:45.811250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 15.75GiB freeMemory: 15.34GiB\n",
      "2019-06-20 03:08:45.811301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-20 03:08:46.306063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-20 03:08:46.306123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-20 03:08:46.306134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-20 03:08:46.306539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14839 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "2019-06-20 03:10:26.215566: I tensorflow/stream_executor/dso_loader.cc:153] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "3236/3236 [==============================] - 35s 11ms/step\n",
      "confusion matrix:\n",
      "[[2790   72]\n",
      " [ 257  117]]\n",
      "accuracy = 0.898331284523\n",
      "precision class 0 = 0.915654718876\n",
      "precision class 1 = 0.619047641754\n",
      "recall class 0 = 0.974842786789\n",
      "recall class 1 = 0.312834233046\n",
      "AUC of ROC = 0.85635395763\n",
      "AUC of PRC = 0.48256979815\n",
      "min(+P, Se) = 0.477333333333\n"
     ]
    }
   ],
   "source": [
    "!python in_hospital_mortality/main.py --network models/lstm.py --dim 16 --timestep 1.0 --depth 2 --dropout 0.3 --mode test --batch_size 8 --load_state in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch28.test0.285991463893.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='in_hospital_mortality/../../data/in-hospital-mortality/', deep_supervision=False, depth=2, dim=16, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch36.test0.280963975335.state', lr=0.001, mode='test', network='models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='.', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model models/lstm.py\n",
      "==> not used params in network class: ['verbose', 'timestep', 'epochs', 'header', 'prefix', 'load_state', 'optimizer', 'network', 'lr', 'output_dir', 'mode', 'size_coef', 'target_repl_coef', 'batch_size', 'data', 'save_every', 'beta_1', 'imputation', 'l2', 'small_part', 'l1', 'normalizer_state']\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "==> model.final_name: k_lstm.n16.d0.3.dep2.bs8.ts1.0\n",
      "==> compiling the model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 16)          5440      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,569\n",
      "Trainable params: 7,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2019-06-20 03:26:39.147414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-20 03:26:39.148062: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x55eb75704940 executing computations on platform CUDA. Devices:\n",
      "2019-06-20 03:26:39.148103: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2019-06-20 03:26:39.150720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-06-20 03:26:39.150963: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x55eb7576d4a0 executing computations on platform Host. Devices:\n",
      "2019-06-20 03:26:39.150993: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-20 03:26:39.151520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 15.75GiB freeMemory: 15.34GiB\n",
      "2019-06-20 03:26:39.151554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-20 03:26:39.652733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-20 03:26:39.652794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-20 03:26:39.652806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-20 03:26:39.653247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14839 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "2019-06-20 03:28:19.638695: I tensorflow/stream_executor/dso_loader.cc:153] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "3236/3236 [==============================] - 34s 10ms/step\n",
      "confusion matrix:\n",
      "[[2800   62]\n",
      " [ 260  114]]\n",
      "accuracy = 0.900494456291\n",
      "precision class 0 = 0.915032684803\n",
      "precision class 1 = 0.647727251053\n",
      "recall class 0 = 0.978336811066\n",
      "recall class 1 = 0.304812848568\n",
      "AUC of ROC = 0.856778102894\n",
      "AUC of PRC = 0.485015859371\n",
      "min(+P, Se) = 0.481578947368\n"
     ]
    }
   ],
   "source": [
    "!python in_hospital_mortality/main.py --network models/lstm.py --dim 16 --timestep 1.0 --depth 2 --dropout 0.3 --mode test --batch_size 8 --load_state in_hospital_mortality/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch36.test0.280963975335.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
